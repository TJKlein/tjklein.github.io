## Tassilo J. Klein, Ph.D. - Bridging Research and Impact in AI

I am a Principal Research Scientist and research manager at the SAP AI CTO Office, spearheading innovation in  Natural Language Processing (NLP) and its intersection with machine learning for structured data. My work focuses on developing cutting-edge AI solutions with real-world impact.

Before joining SAP, I honed my research skills as a postdoctoral fellow at Harvard Medical School and MIT CSAIL, where I investigated large-scale machine learning and optimization for discovering genetically driven imaging biomarkers.  My doctoral research at the Technical University of Munich (TUM) further solidified my expertise in the application of machine learning to medical imaging, focusing on raw ultrasound data processing for early disease detection.

I am also a proud member of the European Laboratory for Learning and Intelligent Systems (ELLIS).


## Research Focus

My current research focuses on the intersection of Natural Language Processing (NLP) and structured data, particularly table representation learning, along with other related areas.


## Recent Publications & Projects

I'm passionate about disseminating research findings and contributing to the open-source community.  A selection of my recent work includes:


[2024.10] - Two papers accepted at the [NeurIPS'24 Table Representation Learning Workshop](https://table-representation-learning.github.io/)
* SALT: Sales Autocompletion Linked Business Tables Dataset - [pre-print](https://openreview.net/forum?id=UZbELpkWIr)
* PORTAL: Scalable Tabular Foundation Models via Content-Specific Tokenization - [pre-print](https://openreview.net/forum?id=TSZQvknbLO)

[2024.01] -  Pre-print available on Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models

[![arXiv](https://img.shields.io/badge/arXiv-2109.05105-29d634.svg)](https://arxiv.org/abs/2401.08491) 

[2023.05] - Paper accepted at [ACL 2023](https://www.2022.aclweb.org/) on low-shot contrastive learning of sentence representations.

[![arXiv](https://img.shields.io/badge/arXiv-2109.05105-29d634.svg)](https://arxiv.org/abs/2211.04928) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/SAP-samples/acl2023-micse/) [![Download Model](https://img.shields.io/badge/-HuggingFace%20Transformer-orange)](https://huggingface.co/sap-ai-research/miCSE)

[2022.02] Paper accepted at [ACL 2022](https://www.2022.aclweb.org/) on self-supervised sentence representation learning 

 [![arXiv](https://img.shields.io/badge/arXiv-2109.05105-29d634.svg)](https://arxiv.org/abs/2203.07847) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/SAP-samples/acl2022-self-contrastive-decorrelation/) 

[2021.08] Paper at [EMNLP 2021](https://2021.emnlp.org/) on Contrastive Language Model Refinement for Commonsense Reasoning

[![arXiv](https://img.shields.io/badge/arXiv-2109.05105-29d634.svg)](https://arxiv.org/abs/2109.05105) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/SAP-samples/emnlp2021-contrastive-refinement/) [![video](https://img.shields.io/badge/YouTube-video-grey?logo=youtube&labelColor=FF0000)](https://underline.io/lecture/37666-towards-zero-shot-commonsense-reasoning-with-self-supervised-refinement-of-language-models)

[2021.08] Paper at [EMNLP 2021](https://2021.emnlp.org/) on Contrastive Self-Supervised Learning for Commonsense Reasoning

[![arXiv](https://img.shields.io/badge/arXiv-2109.05108-29d634.svg)](https://arxiv.org/abs/2109.05108) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/SAP-samples/emnlp2021-attention-contrastive-learning/)

[2021.04] Acceptance of co-organized at [ICML 2021 workshop](https://icml21ssl.github.io/index.html) on Self-Supervised Learning for Reasoning and Perception 

[2021.02] Paper accepted at [IPMI 2021](https://ipmi2021.org/) on self-supervised representation learning for medical imaging (acceptance rate 30.0%)

[![arXiv](https://img.shields.io/badge/arXiv-1912.05396-29d634.svg)](https://arxiv.org/abs/1912.05396) 

[2020.09] Presentation on commonsense reasoning in AI

[![video](https://img.shields.io/badge/YouTube-video-grey?logo=youtube&labelColor=FF0000)](https://youtu.be/AdA6aJpxFfM?t=2457) [![Medium](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/sap-machine-learning-research/common-sense-still-not-common-in-ai-9d68f431e17f?source=friends_link&sk=667a5243eba0e5c19b28941ce8bd1082)

[2020.04] Paper accepted at [ACL 2020](https://acl2020.org/) on contrastive self-supervised commonsense reasoning (acceptance rate of 17.6%)

[![arXiv](https://img.shields.io/badge/arXiv-2005.00669-29d634.svg)](https://arxiv.org/abs/2005.00669) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/SAP-samples/acl2019-commonsense-reasoning) [![video](https://img.shields.io/badge/YouTube-video-grey?logo=youtube&labelColor=FF0000)](http://slideslive.com/38929108)

[2020.02] Paper accepted at  [NeuroImage](https://www.journals.elsevier.com/neuroimage)

[![arXiv](https://img.shields.io/badge/arXiv-1702.08192-29d634.svg)](https://arxiv.org/abs/1702.08192) 

[2019.10.20] Paper on Multi-Domain Learning accepted at [ICCV 2019](http://iccv2019.thecvf.com/) (acceptance rate 25.0%)

[![arXiv](https://img.shields.io/badge/arXiv-1905.06242-29d634.svg)](https://arxiv.org/abs/1905.06242)

[2019.05.14] Short-paper on commonsense reasoning accepted at [ACL 2019](http://www.acl2019.org/EN/index.xhtml) (acceptance rate 18.2%)

[![arXiv](https://img.shields.io/badge/arXiv-1905.13497-29d634.svg)](https://arxiv.org/abs/1905.13497) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/SAP-samples/acl2019-commonsense-reasoning) [![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](https://github.com/SAP-samples/acl2019-commonsense/blob/main/MAS_Example.ipynb)

[2019.02.25] Paper accepted at [CVPR 2019](http://cvpr2019.thecvf.com/) (acceptance rate 25.2%)

[![arXiv](https://img.shields.io/badge/arXiv-1904.03137-29d634.svg)](https://arxiv.org/abs/1904.03137) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/SAP/machine-learning-dgm)

[2017.02.01] Paper accepted at [NeuroImage](https://www.journals.elsevier.com/neuroimage)

[![arXiv](https://img.shields.io/badge/arXiv-1702.08192-29d634.svg)](https://arxiv.org/abs/1702.08192) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/TJKlein/DeepNAT)



##  Collaborations & Mentorship

I am actively involved in mentoring and collaborating with researchers. I also contribute to the research community as a reviewer for conferences such as ACL, CVPR, EMNLP, and workshops like the TLR Workshop. My current interests include exploring table representation learning, neurosymbolic reasoning, and diffusion models for text and tables.  Please feel free to connect on LinkedIn.


**(Last updated: March 15, 2025)**
