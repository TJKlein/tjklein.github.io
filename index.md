Currently, I am research scientist at [SAP AI Research](https://www.sap.com/germany/products/artificial-intelligence/research.html) in Berlin, Germany as well as scientific advisor of [MESASIGHT](https://www.mesasight.com/).
Prior to joining SAP, I was a postdoctoral research fellow at Harvard Medical School, Brigham & Women's Hospital, Boston, in the group of [Sandy Wells](https://lmi.med.harvard.edu/people/william-wells). At the same time, I was a postdoctoral research associate in the Computer Science and Artificial Intelligence Laboratory (CSAIL) at MIT, working with the group of [Polina Goland](https://people.csail.mit.edu/polina/index.html). During that time I was conducting research on large-scale machine learning and optimization technologies for discriminative pattern discovery of genetically driven imaging biomarkers.
I obtained my Ph.D. from Technical University of Munich (TUM) at the intersection of medical imaging and machine learning (raw ultraound data processing for applications such as early detection of Parkinson's disease), advised by [Nassir Navab](http://campar.in.tum.de/Main/NassirNavab).

### Research

<div id="observablehq-chart-9ad5b440"></div>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DEZEKX2WTM"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DEZEKX2WTM');
</script>
<script type="module">
import {Runtime, Inspector, Library} from "https://cdn.jsdelivr.net/npm/@observablehq/runtime@4/dist/runtime.js";
const runtime = new Runtime(Object.assign(new Library, {width: 640}));
import define from "https://api.observablehq.com/@tjklein/transformer-language-model-dynamics.js?v=3";
new Runtime().module(define, name => {
  if (name === "chart") return new Inspector(document.querySelector("#observablehq-chart-9ad5b440"));
});
</script>
|:--:| 
| Snapshot visualization of Transformer language model dynamics (more info coming soon) |

My research interests lie in natural language processing (NLP) and at the intersection of NLP computer vision. I am particularly interested in efficient self-supervised representation learning and continual learning. Although not my current main focus, I am very much interested in machine learning in the medical domain.


### News
**[2022.02]** Paper accepted at [ACL 2022](https://www.2022.aclweb.org/) on self-supervised sentence representation learning 

 [![arXiv](https://img.shields.io/badge/arXiv-2109.05105-29d634.svg)](https://arxiv.org/abs/2203.07847) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/SAP-samples/acl2022-self-contrastive-decorrelation/) 

[2021.08] Paper at [EMNLP 2021](https://2021.emnlp.org/) on Contrastive Language Model Refinement for Commonsense Reasoning

[![arXiv](https://img.shields.io/badge/arXiv-2109.05105-29d634.svg)](https://arxiv.org/abs/2109.05105) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/SAP-samples/emnlp2021-contrastive-refinement/) [![video](https://img.shields.io/badge/YouTube-video-grey?logo=youtube&labelColor=FF0000)](https://underline.io/lecture/37666-towards-zero-shot-commonsense-reasoning-with-self-supervised-refinement-of-language-models)

[2021.08] Paper at [EMNLP 2021](https://2021.emnlp.org/) on Contrastive Self-Supervised Learning for Commonsense Reasoning

[![arXiv](https://img.shields.io/badge/arXiv-2109.05108-29d634.svg)](https://arxiv.org/abs/2109.05108) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/SAP-samples/emnlp2021-attention-contrastive-learning/)

[2021.04] Acceptance of co-organized at [ICML 2021 workshop](https://icml21ssl.github.io/index.html) on Self-Supervised Learning for Reasoning and Perception 

[2021.02] Paper accepted at [IPMI 2021](https://ipmi2021.org/) on self-supervised representation learning for medical imaging (acceptance rate 30.0%)

[![arXiv](https://img.shields.io/badge/arXiv-1912.05396-29d634.svg)](https://arxiv.org/abs/1912.05396) 

[2020.09] Presentation on commonsense reasoning in AI

[![video](https://img.shields.io/badge/YouTube-video-grey?logo=youtube&labelColor=FF0000)](https://youtu.be/AdA6aJpxFfM?t=2457) [![Medium](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/sap-machine-learning-research/common-sense-still-not-common-in-ai-9d68f431e17f?source=friends_link&sk=667a5243eba0e5c19b28941ce8bd1082)

[2020.04] Paper accepted at [ACL 2020](https://acl2020.org/) on contrastive self-supervised commonsense reasoning (acceptance rate of 17.6%)

[![arXiv](https://img.shields.io/badge/arXiv-2005.00669-29d634.svg)](https://arxiv.org/abs/2005.00669) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/SAP-samples/acl2019-commonsense-reasoning) [![video](https://img.shields.io/badge/YouTube-video-grey?logo=youtube&labelColor=FF0000)](http://slideslive.com/38929108)

[2020.02] Paper accepted at  [NeuroImage](https://www.journals.elsevier.com/neuroimage)

[![arXiv](https://img.shields.io/badge/arXiv-1702.08192-29d634.svg)](https://arxiv.org/abs/1702.08192) 

[2019.10.20] Paper on Multi-Domain Learning accepted at [ICCV 2019](http://iccv2019.thecvf.com/) (acceptance rate 25.0%)

[![arXiv](https://img.shields.io/badge/arXiv-1905.06242-29d634.svg)](https://arxiv.org/abs/1905.06242)

[2019.05.14] Short-paper on commonsense reasoning accepted at [ACL 2019](http://www.acl2019.org/EN/index.xhtml) (acceptance rate 18.2%)

[![arXiv](https://img.shields.io/badge/arXiv-1905.13497-29d634.svg)](https://arxiv.org/abs/1905.13497) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/SAP-samples/acl2019-commonsense-reasoning) [![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](https://github.com/SAP-samples/acl2019-commonsense/blob/main/MAS_Example.ipynb)

[2019.02.25] Paper accepted at [CVPR 2019](http://cvpr2019.thecvf.com/) (acceptance rate 25.2%)

[![arXiv](https://img.shields.io/badge/arXiv-1904.03137-29d634.svg)](https://arxiv.org/abs/1904.03137) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/SAP/machine-learning-dgm)

[2017.02.01] Paper accept at [NeuroImage](https://www.journals.elsevier.com/neuroimage)

[![arXiv](https://img.shields.io/badge/arXiv-1702.08192-29d634.svg)](https://arxiv.org/abs/1702.08192) [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/TJKlein/DeepNAT)


*[last update: 11/09/2022]*

